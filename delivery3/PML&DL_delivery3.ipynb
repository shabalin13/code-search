{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shabalin13/code-search/blob/main/delivery3/PML%26DL_delivery3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_9XKAZsOrkx"
      },
      "source": [
        "#Delivery 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwgJ6sOwJpVi"
      },
      "source": [
        "##Implementing search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkGRYCMkuzWR",
        "outputId": "5e9da1c0-0441-445a-8406-9e44657b530a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "EMBEDDINGS_PRECOMPUTED = True\n",
        "EMBEDDINGS_ON_GOOGLE_DRIVE = True\n",
        "if EMBEDDINGS_ON_GOOGLE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230,
          "referenced_widgets": [
            "77fbddfb1fe34f499c6455e2c634066a",
            "56331750d9b54d8e9825c594a1233422",
            "69158801f36a43a7b8ff0c8751dd033a",
            "925365488adc445698173ac322a8e3ac",
            "fdb500c0594b4f6f8d287cb5e31bfabd",
            "2049694736d14ef09df020624ac0d612",
            "7e810c0513a24cd49ccfad72c5fd15a9",
            "5c746b2587e54927870a056039796c19",
            "248fda69a87e43d28aec994ba3765355",
            "20e7fbacbecb47c0a0de5495aed0e333",
            "feb47f1675c14f3d813080553ba669f6"
          ]
        },
        "id": "sZVy_I93rRkw",
        "outputId": "428a0179-7ba8-4a88-de27-a93a809ec7e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp-dev is already the newest version (5.0.1-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset code_x_glue_ct_code_to_text (/root/.cache/huggingface/datasets/code_x_glue_ct_code_to_text/python/0.0.0/f8b7e9d51f609a87e7ec7c7431706d4ee0b402e3398560410313d4acc67060a0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77fbddfb1fe34f499c6455e2c634066a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install transformers --quiet\n",
        "!pip install datasets --quiet\n",
        "!apt install libomp-dev\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch.utils.data import DataLoader\n",
        "from enum import Enum, auto\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device == 'cuda':\n",
        "    !pip install faiss-gpu -q\n",
        "else:\n",
        "    !pip install faiss -q\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "dataset = load_dataset(\"code_x_glue_ct_code_to_text\", 'python')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8kAFcx2gPNuf"
      },
      "outputs": [],
      "source": [
        "train_data, valid_data, test_data = dataset['train'], dataset['validation'], dataset['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JsWA3IKdSnQd"
      },
      "outputs": [],
      "source": [
        "class SeqType(Enum):\n",
        "  CODE = auto()\n",
        "  DOC = auto()\n",
        "\n",
        "\n",
        "class TokenizeCollator(object):\n",
        "    def __init__(self, tokenizer, seq_type):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.seq_type = seq_type\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        return self.create_one_batch(batch)\n",
        "\n",
        "    def create_one_batch(self, batch):\n",
        "        tokens_batch = list(map(lambda item: self.get_formatted_input(item), batch))\n",
        "        batch_encoding = self.tokenizer(tokens_batch, padding=True, return_tensors='pt', return_token_type_ids=True, truncation=True)\n",
        "        tokens_ids = batch_encoding.input_ids.to(device)\n",
        "        token_type_ids = batch_encoding.token_type_ids.to(device)\n",
        "        attention_mask = batch_encoding.attention_mask.to(device)\n",
        "        return tokens_ids, token_type_ids, attention_mask\n",
        "\n",
        "    def get_formatted_input(self, item):\n",
        "        if self.seq_type == SeqType.CODE:\n",
        "            return self.get_formatted_input_for_code(item)\n",
        "        elif self.seq_type == SeqType.DOC:\n",
        "            return self.get_formatted_input_for_doc(item)\n",
        "        else:\n",
        "            raise Exception(\"Incorrect sequence type\")\n",
        "\n",
        "    def get_formatted_input_for_code(self, item):\n",
        "        doc_tokens = ' '.join(item['docstring_tokens'])\n",
        "        code_tokens = ' '.join(item['code_tokens'])\n",
        "        formatted_input = self.tokenizer.cls_token + doc_tokens + self.tokenizer.sep_token+code_tokens + self.tokenizer.sep_token\n",
        "        return formatted_input\n",
        "\n",
        "    def get_formatted_input_for_doc(self, item):\n",
        "        doc_tokens = ' '.join(item['docstring_tokens'])\n",
        "        code_tokens = ''\n",
        "        formatted_input = self.tokenizer.cls_token + doc_tokens + self.tokenizer.sep_token+code_tokens + self.tokenizer.sep_token\n",
        "        return formatted_input \n",
        "\n",
        "\n",
        "code_tokenize_collate_fn = TokenizeCollator(tokenizer, SeqType.CODE)\n",
        "doc_tokenize_collate_fn = TokenizeCollator(tokenizer, SeqType.DOC)\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "test_code_tokens_ids = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=code_tokenize_collate_fn, num_workers=0)\n",
        "test_doc_tokens_ids = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=doc_tokenize_collate_fn, num_workers=0)\n",
        "\n",
        "# for idx, batch in enumerate(test_tokens_ids):\n",
        "#   # print(batch.shape)\n",
        "#   print(batch)\n",
        "#   if idx >= 0:\n",
        "#     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w0r54Nk7cJLK"
      },
      "outputs": [],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "def print_gpu_memory_usage(idx=''):\n",
        "    print(idx)\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
        "    print()\n",
        "\n",
        "\n",
        "if not EMBEDDINGS_PRECOMPUTED:\n",
        "    batched_test_code_embs = []\n",
        "    for batch in tqdm(test_code_tokens_ids):\n",
        "        tokens_ids, token_type_ids, attention_mask = batch\n",
        "        with torch.no_grad():\n",
        "            embs = model(input_ids=tokens_ids, token_type_ids=token_type_ids, attention_mask=attention_mask).pooler_output\n",
        "            batched_test_code_embs.append(embs)\n",
        "\n",
        "    batched_test_doc_embs = []\n",
        "    for batch in tqdm(test_doc_tokens_ids):\n",
        "        tokens_ids, token_type_ids, attention_mask = batch\n",
        "        with torch.no_grad():\n",
        "            embs = model(input_ids=tokens_ids, token_type_ids=token_type_ids, attention_mask=attention_mask).pooler_output\n",
        "            batched_test_doc_embs.append(embs)\n",
        "\n",
        "    test_code_embeddings = torch.cat(batched_test_code_embs, dim=0)\n",
        "    test_doc_embeddings = torch.cat(batched_test_doc_embs, dim=0)\n",
        "    if EMBEDDINGS_ON_GOOGLE_DRIVE:\n",
        "        %cd /content/drive/MyDrive/PML&DL/Project\n",
        "    torch.save(test_code_embeddings, 'test_code_embeddings.pt')\n",
        "    torch.save(test_doc_embeddings, 'test_doc_embeddings.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cph_ZnGjEa7",
        "outputId": "c793edcf-d12d-42c9-beb2-1b0530366225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PML&DL/Project\n"
          ]
        }
      ],
      "source": [
        "if EMBEDDINGS_PRECOMPUTED:\n",
        "    if EMBEDDINGS_ON_GOOGLE_DRIVE:\n",
        "        %cd /content/drive/MyDrive/PML&DL/Project\n",
        "    test_code_embeddings = torch.load('test_code_embeddings.pt', map_location=torch.device('cpu'))\n",
        "    test_doc_embeddings = torch.load('test_doc_embeddings.pt', map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gAueILqgAJkh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "\n",
        "class FaissKNeighbors:\n",
        "    def __init__(self, is_cuda):\n",
        "        self.index = None\n",
        "        self.is_cuda = is_cuda\n",
        "\n",
        "    def fit(self, X):\n",
        "        self.index = faiss.IndexFlatL2(X.shape[1])\n",
        "        if self.is_cuda:\n",
        "            res = faiss.StandardGpuResources()\n",
        "            self.index = faiss.index_cpu_to_gpu(res, 0, self.index)\n",
        "        if type(X) == torch.Tensor:\n",
        "            X = X.numpy()\n",
        "        self.index.add(X)\n",
        "\n",
        "    def predict(self, X, k):\n",
        "        if type(X) == torch.Tensor:\n",
        "            X = X.numpy()\n",
        "        distances, indices = self.index.search(X, k=k)\n",
        "        return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IE9YRj_dAKKP"
      },
      "outputs": [],
      "source": [
        "test_faiss = FaissKNeighbors(is_cuda=device=='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_code_model_input = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=code_tokenize_collate_fn, num_workers=0)\n",
        "test_doc_model_input = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=doc_tokenize_collate_fn, num_workers=0)"
      ],
      "metadata": {
        "id": "2wElvUcZrXT6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(code_dataloader, doc_dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    batched_val_code_embs = []\n",
        "    batched_val_doc_embs = []\n",
        "\n",
        "    running_loss = 0\n",
        "    for iteration, (code_tokens, doc_tokens) in tqdm(enumerate(zip(code_dataloader, doc_dataloader)), total=len(code_dataloader)):\n",
        "        with torch.no_grad():\n",
        "            tokens_ids, token_type_ids, attention_mask = code_tokens\n",
        "            code_embs = model(input_ids=tokens_ids, token_type_ids=token_type_ids, attention_mask=attention_mask).pooler_output\n",
        "            tokens_ids, token_type_ids, attention_mask = doc_tokens\n",
        "            doc_embs = model(input_ids=tokens_ids, token_type_ids=token_type_ids, attention_mask=attention_mask).pooler_output\n",
        "\n",
        "            loss = loss_fn(doc_embs, code_embs)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            batched_val_code_embs.append(code_embs)\n",
        "            batched_val_doc_embs.append(doc_embs)\n",
        "\n",
        "    val_code_embeddings = torch.cat(batched_val_code_embs, dim=0)\n",
        "    val_doc_embeddings = torch.cat(batched_val_doc_embs, dim=0)\n",
        "\n",
        "    loss = running_loss / len(code_dataloader)\n",
        "\n",
        "    k = 1000\n",
        "    mrrs = []\n",
        "    for beg_idx in range(0, len(val_code_embeddings), k):\n",
        "        if beg_idx + k > len(val_code_embeddings):\n",
        "            k = len(val_code_embeddings) - beg_idx\n",
        "        doc_embs_subset = val_doc_embeddings[beg_idx:beg_idx + k]\n",
        "        code_embs_subset = val_code_embeddings[beg_idx:beg_idx + k]\n",
        "        test_faiss.fit(code_embs_subset)  \n",
        "        preds = test_faiss.predict(doc_embs_subset, k=k)\n",
        "\n",
        "        targets = np.repeat(np.expand_dims(range(k), 1), k, axis=1)\n",
        "\n",
        "        reciprocal_ranks = 1 / (np.argwhere(np.equal(preds, targets))[:,1] + 1)\n",
        "        mrr_ = np.mean(reciprocal_ranks)\n",
        "        mrrs.append(mrr_)\n",
        "    \n",
        "    return np.mean(mrrs), loss"
      ],
      "metadata": {
        "id": "z09lcYYRaP3k"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrr, loss = eval(test_code_model_input, test_doc_model_input)\n",
        "print('Mean Reciprocal rank is: ', mrr)"
      ],
      "metadata": {
        "id": "YHbAHZ1RrL3-",
        "outputId": "5901618c-d284-47a1-e6c0-e892d5a3b83e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 117/117 [08:56<00:00,  4.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Reciprocal rank is:  0.023664168635244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Delivery 3"
      ],
      "metadata": {
        "id": "xrOnff1tIHLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class FineTunedCodeBert:\n",
        "#     def __init__(self, model, is_freeze_bert=True):\n",
        "#         self.model = model\n",
        "\n",
        "#         if is_freeze_bert:\n",
        "#             for p in self.model.parameters():\n",
        "#                 p.requires_grad = False\n",
        "#             for p in self.model.pooler.parameters():\n",
        "#                 p.requires_grad = True\n",
        "\n",
        "#     def forward(self, X):\n",
        "#         tokens_ids, token_type_ids, attention_mask = X\n",
        "#         embs = self.model(input_ids=tokens_ids, token_type_ids=token_type_ids, attention_mask=attention_mask).pooler_output\n",
        "#         return embs\n",
        "\n",
        "\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model.pooler.parameters():\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "NeW0rxvKIOzt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-5\n",
        "epochs = 8\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "3cXmwYZBSBlr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(code_dataloader, doc_dataloader, val_code_dataloader, val_doc_dataloader, epoch):\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for iteration, (code_tokens, doc_tokens) in tqdm(enumerate(zip(code_dataloader, doc_dataloader)), total=len(code_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        with torch.autocast(device_type=device, dtype=torch.float16):\n",
        "            tokens_ids, token_type_ids, attention_mask = code_tokens\n",
        "            code_embs = model(input_ids=tokens_ids, token_type_ids=token_type_ids, attention_mask=attention_mask).pooler_output\n",
        "            tokens_ids, token_type_ids, attention_mask = doc_tokens\n",
        "            doc_embs = model(input_ids=tokens_ids, token_type_ids=token_type_ids, attention_mask=attention_mask).pooler_output\n",
        "        loss = loss_fn(doc_embs, code_embs)\n",
        "        running_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if iteration % 50 == 0:\n",
        "            _loss = running_loss / (iteration + 1)\n",
        "            print(\"epoch: {}\\titeration: {}\\tloss: {}\\tthis iteration loss: {}\".format(epoch, iteration, _loss, loss))\n",
        "\n",
        "    print(\"epoch: {}\\ttrain loss: {}\".format(epoch, running_loss / len(code_dataloader)))\n",
        "\n",
        "    torch.save(model, 'codebert.pt')\n",
        "\n",
        "    mrr, loss = eval(val_code_dataloader, val_doc_dataloader)\n",
        "    print(\"epoch: {}\\tvalid loss: {}\\tmrr: {}\".format(epoch, loss, mrr))\n"
      ],
      "metadata": {
        "id": "V0iAdf1UTSbC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_code_model_input = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=code_tokenize_collate_fn, num_workers=0)\n",
        "train_doc_model_input = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=doc_tokenize_collate_fn, num_workers=0)\n",
        "val_code_model_input = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=code_tokenize_collate_fn, num_workers=0)\n",
        "val_doc_model_input = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=doc_tokenize_collate_fn, num_workers=0)\n"
      ],
      "metadata": {
        "id": "PoUXAoaOX9rH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    train(train_code_model_input, train_doc_model_input, val_code_model_input, val_doc_model_input, epoch)"
      ],
      "metadata": {
        "id": "tinECtM3XURX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "884994f1-ad49-4c49-bf62-f33136058c8d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1968 [00:04<2:37:24,  4.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 0\tloss: 0.03290637582540512\tthis iteration loss: 0.03290637582540512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 51/1968 [04:30<2:45:38,  5.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0\titeration: 50\tloss: 0.022629147066789514\tthis iteration loss: 0.020183777436614037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▍         | 94/1968 [08:23<2:47:22,  5.36s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-19a97a461159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_code_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_doc_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_code_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_doc_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-32fd979e64a6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(code_dataloader, doc_dataloader, val_code_dataloader, val_doc_dataloader, epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdoc_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_embs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "77fbddfb1fe34f499c6455e2c634066a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56331750d9b54d8e9825c594a1233422",
              "IPY_MODEL_69158801f36a43a7b8ff0c8751dd033a",
              "IPY_MODEL_925365488adc445698173ac322a8e3ac"
            ],
            "layout": "IPY_MODEL_fdb500c0594b4f6f8d287cb5e31bfabd"
          }
        },
        "56331750d9b54d8e9825c594a1233422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2049694736d14ef09df020624ac0d612",
            "placeholder": "​",
            "style": "IPY_MODEL_7e810c0513a24cd49ccfad72c5fd15a9",
            "value": "100%"
          }
        },
        "69158801f36a43a7b8ff0c8751dd033a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c746b2587e54927870a056039796c19",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_248fda69a87e43d28aec994ba3765355",
            "value": 3
          }
        },
        "925365488adc445698173ac322a8e3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20e7fbacbecb47c0a0de5495aed0e333",
            "placeholder": "​",
            "style": "IPY_MODEL_feb47f1675c14f3d813080553ba669f6",
            "value": " 3/3 [00:00&lt;00:00, 64.33it/s]"
          }
        },
        "fdb500c0594b4f6f8d287cb5e31bfabd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2049694736d14ef09df020624ac0d612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e810c0513a24cd49ccfad72c5fd15a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c746b2587e54927870a056039796c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "248fda69a87e43d28aec994ba3765355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20e7fbacbecb47c0a0de5495aed0e333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feb47f1675c14f3d813080553ba669f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}